{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "dfeb4fde596e3a1dcfe636c6f699694a0598ebf6bf1090fe149a85f84a3e4452"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "class CharacterTable:\n",
    "    \"\"\"与えられた文字のセット:\n",
    "    + One Hot 表現にエンコードする\n",
    "    + ワンホットまたは整数表現を文字出力にデコードする\n",
    "    + 確率ベクトルを文字出力にデコードします\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"文字テーブルを初期化\n",
    "        # 引数\n",
    "            chars: 入力に表示できる文字。\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"与えられた文字列 C の one-hot エンコード\n",
    "        # 引数\n",
    "            C: 文字列。エンコードされる。\n",
    "            num_rows: 返されたワンホットエンコーディングの行数。これは、各データの行数を同じに保つために使用される。\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"指定されたベクトルまたは二次元配列を文字出力にデコードします。\n",
    "        # 引数\n",
    "            x: 確率またはワンホット表現のベクトルまたは二次元配列;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(\"Total questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vectorization...\nTraining Data:\n(45000, 7, 12)\n(45000, 4, 12)\nValidation Data:\n(5000, 7, 12)\n(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "num_layers = 1  # Try to add more LSTM layers!\n",
    "\n",
    "model = keras.Sequential()\n",
    "# LSTMを使用して入力シーケンスを「エンコード」する\n",
    "# 入力シーケンスの長さが可変である状況では、input_shape =(None、num_feature)\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "# デコーダーのRNNの入力として、タイムステップごとにRNNの最後の出力を繰り返し提供します。\n",
    "# 'DIGITS + 1'を繰り返します。これは出力の最大長です。たとえば、DIGITS = 3の場合、最大出力は999 + 999 = 1998です。\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# デコーダーRNNは、スタックされた複数のレイヤーまたは単一のレイヤーにすることができます。\n",
    "for _ in range(num_layers):\n",
    "    # return_sequencesをTrueに設定すると、最後の出力だけでなく、これまでのすべての出力が（num_samples、timesteps、output_dim）の形式で返されます。\n",
    "    # 以下のTimeDistributedは、最初のディメンションがタイムステップであると想定しているため、これが必要です。\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# 入力のすべての時間スライスに密なレイヤーを適用します。出力シーケンスの各ステップで、どの文字を選択するかを決定します。\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Iteration 1\n",
      "1407/1407 [==============================] - 29s 19ms/step - loss: 1.8824 - accuracy: 0.3248 - val_loss: 1.5426 - val_accuracy: 0.4265\n",
      "Q 63+825  T 888  ☒ 901 \n",
      "Q 474+28  T 502  ☒ 496 \n",
      "Q 70+22   T 92   ☒ 10  \n",
      "Q 54+978  T 1032 ☒ 101 \n",
      "Q 8+706   T 714  ☒ 886 \n",
      "Q 262+6   T 268  ☒ 666 \n",
      "Q 51+548  T 599  ☒ 556 \n",
      "Q 676+597 T 1273 ☒ 1266\n",
      "Q 311+26  T 337  ☒ 223 \n",
      "Q 36+95   T 131  ☒ 166 \n",
      "\n",
      "Iteration 2\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.3336 - accuracy: 0.5017 - val_loss: 1.1797 - val_accuracy: 0.5517\n",
      "Q 88+804  T 892  ☒ 874 \n",
      "Q 680+117 T 797  ☒ 744 \n",
      "Q 16+808  T 824  ☒ 829 \n",
      "Q 19+48   T 67   ☒ 59  \n",
      "Q 698+205 T 903  ☒ 774 \n",
      "Q 15+305  T 320  ☒ 349 \n",
      "Q 93+68   T 161  ☒ 144 \n",
      "Q 72+717  T 789  ☒ 777 \n",
      "Q 549+659 T 1208 ☒ 1174\n",
      "Q 35+323  T 358  ☒ 349 \n",
      "\n",
      "Iteration 3\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.0517 - accuracy: 0.6088 - val_loss: 0.9683 - val_accuracy: 0.6392\n",
      "Q 252+34  T 286  ☒ 283 \n",
      "Q 77+669  T 746  ☒ 735 \n",
      "Q 69+528  T 597  ☒ 695 \n",
      "Q 8+470   T 478  ☒ 475 \n",
      "Q 21+890  T 911  ☒ 905 \n",
      "Q 9+787   T 796  ☒ 795 \n",
      "Q 44+324  T 368  ☒ 366 \n",
      "Q 462+25  T 487  ☒ 486 \n",
      "Q 255+49  T 304  ☒ 303 \n",
      "Q 2+230   T 232  ☒ 239 \n",
      "\n",
      "Iteration 4\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.9128 - accuracy: 0.6619 - val_loss: 0.8987 - val_accuracy: 0.6504\n",
      "Q 2+664   T 666  ☒ 669 \n",
      "Q 786+891 T 1677 ☒ 1666\n",
      "Q 78+731  T 809  ☑ 809 \n",
      "Q 191+826 T 1017 ☒ 1008\n",
      "Q 12+883  T 895  ☒ 899 \n",
      "Q 747+754 T 1501 ☒ 1412\n",
      "Q 810+244 T 1054 ☒ 903 \n",
      "Q 432+447 T 879  ☒ 769 \n",
      "Q 690+31  T 721  ☒ 719 \n",
      "Q 816+544 T 1360 ☒ 1279\n",
      "\n",
      "Iteration 5\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.8065 - accuracy: 0.7018 - val_loss: 0.7460 - val_accuracy: 0.7293\n",
      "Q 69+252  T 321  ☑ 321 \n",
      "Q 38+349  T 387  ☒ 386 \n",
      "Q 178+713 T 891  ☒ 899 \n",
      "Q 384+866 T 1250 ☒ 1244\n",
      "Q 17+769  T 786  ☑ 786 \n",
      "Q 39+139  T 178  ☒ 186 \n",
      "Q 92+902  T 994  ☒ 990 \n",
      "Q 895+57  T 952  ☒ 954 \n",
      "Q 3+511   T 514  ☒ 513 \n",
      "Q 5+454   T 459  ☑ 459 \n",
      "\n",
      "Iteration 6\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.7028 - accuracy: 0.7427 - val_loss: 0.6470 - val_accuracy: 0.7616\n",
      "Q 608+352 T 960  ☒ 953 \n",
      "Q 278+6   T 284  ☒ 283 \n",
      "Q 14+934  T 948  ☒ 947 \n",
      "Q 306+84  T 390  ☒ 380 \n",
      "Q 35+309  T 344  ☒ 351 \n",
      "Q 935+48  T 983  ☒ 984 \n",
      "Q 924+737 T 1661 ☒ 1655\n",
      "Q 53+94   T 147  ☒ 148 \n",
      "Q 9+249   T 258  ☒ 266 \n",
      "Q 660+509 T 1169 ☒ 1168\n",
      "\n",
      "Iteration 7\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5388 - accuracy: 0.8059 - val_loss: 0.4316 - val_accuracy: 0.8407\n",
      "Q 5+236   T 241  ☒ 242 \n",
      "Q 41+592  T 633  ☑ 633 \n",
      "Q 60+997  T 1057 ☒ 1067\n",
      "Q 239+7   T 246  ☒ 247 \n",
      "Q 281+0   T 281  ☒ 282 \n",
      "Q 350+611 T 961  ☒ 962 \n",
      "Q 795+941 T 1736 ☑ 1736\n",
      "Q 174+556 T 730  ☒ 731 \n",
      "Q 931+26  T 957  ☑ 957 \n",
      "Q 63+95   T 158  ☑ 158 \n",
      "\n",
      "Iteration 8\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.3233 - accuracy: 0.8968 - val_loss: 0.2555 - val_accuracy: 0.9227\n",
      "Q 535+89  T 624  ☑ 624 \n",
      "Q 769+585 T 1354 ☒ 1353\n",
      "Q 17+79   T 96   ☒ 98  \n",
      "Q 565+808 T 1373 ☑ 1373\n",
      "Q 22+677  T 699  ☑ 699 \n",
      "Q 161+73  T 234  ☑ 234 \n",
      "Q 477+43  T 520  ☑ 520 \n",
      "Q 66+904  T 970  ☑ 970 \n",
      "Q 920+9   T 929  ☑ 929 \n",
      "Q 742+606 T 1348 ☒ 1357\n",
      "\n",
      "Iteration 9\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 0.1971 - accuracy: 0.9485 - val_loss: 0.1684 - val_accuracy: 0.9534\n",
      "Q 49+638  T 687  ☑ 687 \n",
      "Q 74+571  T 645  ☑ 645 \n",
      "Q 204+46  T 250  ☒ 240 \n",
      "Q 18+532  T 550  ☑ 550 \n",
      "Q 27+914  T 941  ☑ 941 \n",
      "Q 757+439 T 1196 ☑ 1196\n",
      "Q 328+231 T 559  ☒ 569 \n",
      "Q 6+687   T 693  ☑ 693 \n",
      "Q 92+112  T 204  ☑ 204 \n",
      "Q 771+2   T 773  ☑ 773 \n",
      "\n",
      "Iteration 10\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.1311 - accuracy: 0.9680 - val_loss: 0.1262 - val_accuracy: 0.9617\n",
      "Q 99+949  T 1048 ☒ 1058\n",
      "Q 374+427 T 801  ☑ 801 \n",
      "Q 530+877 T 1407 ☑ 1407\n",
      "Q 781+18  T 799  ☑ 799 \n",
      "Q 87+37   T 124  ☑ 124 \n",
      "Q 631+460 T 1091 ☒ 1080\n",
      "Q 27+594  T 621  ☑ 621 \n",
      "Q 813+8   T 821  ☑ 821 \n",
      "Q 49+638  T 687  ☑ 687 \n",
      "Q 909+474 T 1383 ☒ 1382\n",
      "\n",
      "Iteration 11\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0946 - accuracy: 0.9770 - val_loss: 0.1163 - val_accuracy: 0.9648\n",
      "Q 85+75   T 160  ☒ 150 \n",
      "Q 5+906   T 911  ☑ 911 \n",
      "Q 1+376   T 377  ☑ 377 \n",
      "Q 873+810 T 1683 ☑ 1683\n",
      "Q 31+885  T 916  ☑ 916 \n",
      "Q 0+54    T 54   ☒ 55  \n",
      "Q 48+44   T 92   ☑ 92  \n",
      "Q 772+14  T 786  ☑ 786 \n",
      "Q 608+352 T 960  ☒ 969 \n",
      "Q 217+29  T 246  ☑ 246 \n",
      "\n",
      "Iteration 12\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0686 - accuracy: 0.9843 - val_loss: 0.0610 - val_accuracy: 0.9848\n",
      "Q 91+376  T 467  ☑ 467 \n",
      "Q 444+299 T 743  ☑ 743 \n",
      "Q 7+26    T 33   ☑ 33  \n",
      "Q 37+449  T 486  ☑ 486 \n",
      "Q 696+25  T 721  ☑ 721 \n",
      "Q 2+290   T 292  ☑ 292 \n",
      "Q 394+7   T 401  ☑ 401 \n",
      "Q 8+579   T 587  ☑ 587 \n",
      "Q 329+43  T 372  ☑ 372 \n",
      "Q 328+60  T 388  ☑ 388 \n",
      "\n",
      "Iteration 13\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0643 - accuracy: 0.9837 - val_loss: 0.0298 - val_accuracy: 0.9956\n",
      "Q 517+54  T 571  ☑ 571 \n",
      "Q 954+72  T 1026 ☑ 1026\n",
      "Q 947+842 T 1789 ☑ 1789\n",
      "Q 168+564 T 732  ☑ 732 \n",
      "Q 602+940 T 1542 ☑ 1542\n",
      "Q 926+237 T 1163 ☑ 1163\n",
      "Q 335+180 T 515  ☑ 515 \n",
      "Q 47+146  T 193  ☑ 193 \n",
      "Q 2+117   T 119  ☑ 119 \n",
      "Q 93+945  T 1038 ☑ 1038\n",
      "\n",
      "Iteration 14\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0518 - accuracy: 0.9864 - val_loss: 0.0940 - val_accuracy: 0.9712\n",
      "Q 230+15  T 245  ☑ 245 \n",
      "Q 194+0   T 194  ☑ 194 \n",
      "Q 204+906 T 1110 ☒ 1010\n",
      "Q 0+683   T 683  ☑ 683 \n",
      "Q 86+31   T 117  ☑ 117 \n",
      "Q 75+105  T 180  ☑ 180 \n",
      "Q 8+217   T 225  ☑ 225 \n",
      "Q 873+773 T 1646 ☑ 1646\n",
      "Q 800+0   T 800  ☑ 800 \n",
      "Q 96+43   T 139  ☑ 139 \n",
      "\n",
      "Iteration 15\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0352 - accuracy: 0.9916 - val_loss: 0.1624 - val_accuracy: 0.9471\n",
      "Q 24+397  T 421  ☑ 421 \n",
      "Q 961+98  T 1059 ☑ 1059\n",
      "Q 967+4   T 971  ☑ 971 \n",
      "Q 999+807 T 1806 ☑ 1806\n",
      "Q 67+997  T 1064 ☑ 1064\n",
      "Q 893+71  T 964  ☑ 964 \n",
      "Q 356+86  T 442  ☑ 442 \n",
      "Q 503+27  T 530  ☑ 530 \n",
      "Q 837+11  T 848  ☒ 858 \n",
      "Q 10+84   T 94   ☑ 94  \n",
      "\n",
      "Iteration 16\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0369 - accuracy: 0.9906 - val_loss: 0.0137 - val_accuracy: 0.9984\n",
      "Q 347+447 T 794  ☑ 794 \n",
      "Q 75+734  T 809  ☑ 809 \n",
      "Q 90+469  T 559  ☑ 559 \n",
      "Q 69+7    T 76   ☑ 76  \n",
      "Q 172+66  T 238  ☑ 238 \n",
      "Q 259+72  T 331  ☑ 331 \n",
      "Q 582+75  T 657  ☑ 657 \n",
      "Q 235+35  T 270  ☑ 270 \n",
      "Q 0+998   T 998  ☑ 998 \n",
      "Q 541+11  T 552  ☑ 552 \n",
      "\n",
      "Iteration 17\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0342 - accuracy: 0.9908 - val_loss: 0.0207 - val_accuracy: 0.9956\n",
      "Q 185+74  T 259  ☑ 259 \n",
      "Q 4+61    T 65   ☑ 65  \n",
      "Q 128+81  T 209  ☑ 209 \n",
      "Q 817+84  T 901  ☑ 901 \n",
      "Q 845+40  T 885  ☑ 885 \n",
      "Q 12+897  T 909  ☑ 909 \n",
      "Q 641+542 T 1183 ☑ 1183\n",
      "Q 428+6   T 434  ☑ 434 \n",
      "Q 245+701 T 946  ☑ 946 \n",
      "Q 947+71  T 1018 ☑ 1018\n",
      "\n",
      "Iteration 18\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0279 - accuracy: 0.9925 - val_loss: 0.0105 - val_accuracy: 0.9985\n",
      "Q 53+711  T 764  ☑ 764 \n",
      "Q 139+997 T 1136 ☑ 1136\n",
      "Q 95+305  T 400  ☑ 400 \n",
      "Q 915+96  T 1011 ☑ 1011\n",
      "Q 873+773 T 1646 ☑ 1646\n",
      "Q 7+193   T 200  ☒ 100 \n",
      "Q 905+205 T 1110 ☑ 1110\n",
      "Q 2+606   T 608  ☑ 608 \n",
      "Q 60+441  T 501  ☑ 501 \n",
      "Q 174+4   T 178  ☑ 178 \n",
      "\n",
      "Iteration 19\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0354 - accuracy: 0.9904 - val_loss: 0.0116 - val_accuracy: 0.9981\n",
      "Q 563+967 T 1530 ☑ 1530\n",
      "Q 564+25  T 589  ☑ 589 \n",
      "Q 991+6   T 997  ☑ 997 \n",
      "Q 3+430   T 433  ☑ 433 \n",
      "Q 359+2   T 361  ☑ 361 \n",
      "Q 969+682 T 1651 ☑ 1651\n",
      "Q 245+117 T 362  ☑ 362 \n",
      "Q 71+362  T 433  ☑ 433 \n",
      "Q 3+663   T 666  ☑ 666 \n",
      "Q 685+336 T 1021 ☑ 1021\n",
      "\n",
      "Iteration 20\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0279 - accuracy: 0.9924 - val_loss: 0.0267 - val_accuracy: 0.9930\n",
      "Q 818+30  T 848  ☑ 848 \n",
      "Q 140+95  T 235  ☑ 235 \n",
      "Q 17+425  T 442  ☑ 442 \n",
      "Q 84+39   T 123  ☑ 123 \n",
      "Q 4+775   T 779  ☑ 779 \n",
      "Q 378+357 T 735  ☑ 735 \n",
      "Q 32+599  T 631  ☑ 631 \n",
      "Q 71+113  T 184  ☑ 184 \n",
      "Q 466+31  T 497  ☑ 497 \n",
      "Q 4+415   T 419  ☑ 419 \n",
      "\n",
      "Iteration 21\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0183 - accuracy: 0.9955 - val_loss: 0.0090 - val_accuracy: 0.9983\n",
      "Q 147+4   T 151  ☑ 151 \n",
      "Q 720+93  T 813  ☑ 813 \n",
      "Q 124+3   T 127  ☑ 127 \n",
      "Q 75+483  T 558  ☑ 558 \n",
      "Q 23+705  T 728  ☑ 728 \n",
      "Q 12+417  T 429  ☑ 429 \n",
      "Q 114+47  T 161  ☑ 161 \n",
      "Q 903+7   T 910  ☑ 910 \n",
      "Q 176+643 T 819  ☑ 819 \n",
      "Q 628+593 T 1221 ☑ 1221\n",
      "\n",
      "Iteration 22\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0239 - accuracy: 0.9931 - val_loss: 0.0237 - val_accuracy: 0.9936\n",
      "Q 283+40  T 323  ☑ 323 \n",
      "Q 27+666  T 693  ☑ 693 \n",
      "Q 3+108   T 111  ☑ 111 \n",
      "Q 165+820 T 985  ☑ 985 \n",
      "Q 84+751  T 835  ☑ 835 \n",
      "Q 127+165 T 292  ☑ 292 \n",
      "Q 844+648 T 1492 ☑ 1492\n",
      "Q 886+73  T 959  ☑ 959 \n",
      "Q 386+3   T 389  ☑ 389 \n",
      "Q 153+50  T 203  ☑ 203 \n",
      "\n",
      "Iteration 23\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.0069 - val_accuracy: 0.9992\n",
      "Q 71+3    T 74   ☑ 74  \n",
      "Q 578+163 T 741  ☑ 741 \n",
      "Q 729+832 T 1561 ☑ 1561\n",
      "Q 6+999   T 1005 ☑ 1005\n",
      "Q 79+709  T 788  ☑ 788 \n",
      "Q 626+594 T 1220 ☑ 1220\n",
      "Q 406+174 T 580  ☑ 580 \n",
      "Q 991+58  T 1049 ☑ 1049\n",
      "Q 570+28  T 598  ☑ 598 \n",
      "Q 96+986  T 1082 ☑ 1082\n",
      "\n",
      "Iteration 24\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0240 - accuracy: 0.9935 - val_loss: 0.0072 - val_accuracy: 0.9985\n",
      "Q 499+27  T 526  ☑ 526 \n",
      "Q 46+878  T 924  ☑ 924 \n",
      "Q 975+532 T 1507 ☑ 1507\n",
      "Q 30+429  T 459  ☑ 459 \n",
      "Q 4+672   T 676  ☑ 676 \n",
      "Q 74+242  T 316  ☑ 316 \n",
      "Q 918+281 T 1199 ☑ 1199\n",
      "Q 736+76  T 812  ☑ 812 \n",
      "Q 138+81  T 219  ☑ 219 \n",
      "Q 33+741  T 774  ☑ 774 \n",
      "\n",
      "Iteration 25\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0212 - accuracy: 0.9941 - val_loss: 0.0424 - val_accuracy: 0.9867\n",
      "Q 99+11   T 110  ☑ 110 \n",
      "Q 346+19  T 365  ☒ 355 \n",
      "Q 44+265  T 309  ☑ 309 \n",
      "Q 83+75   T 158  ☑ 158 \n",
      "Q 45+456  T 501  ☑ 501 \n",
      "Q 811+401 T 1212 ☑ 1212\n",
      "Q 436+37  T 473  ☑ 473 \n",
      "Q 923+672 T 1595 ☑ 1595\n",
      "Q 207+83  T 290  ☑ 290 \n",
      "Q 399+699 T 1098 ☒ 1088\n",
      "\n",
      "Iteration 26\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0216 - accuracy: 0.9943 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Q 33+168  T 201  ☑ 201 \n",
      "Q 865+25  T 890  ☑ 890 \n",
      "Q 78+258  T 336  ☑ 336 \n",
      "Q 136+844 T 980  ☑ 980 \n",
      "Q 92+691  T 783  ☑ 783 \n",
      "Q 5+496   T 501  ☑ 501 \n",
      "Q 490+678 T 1168 ☑ 1168\n",
      "Q 298+993 T 1291 ☑ 1291\n",
      "Q 25+122  T 147  ☑ 147 \n",
      "Q 97+622  T 719  ☑ 719 \n",
      "\n",
      "Iteration 27\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0209 - accuracy: 0.9941 - val_loss: 0.0304 - val_accuracy: 0.9911\n",
      "Q 62+593  T 655  ☑ 655 \n",
      "Q 632+59  T 691  ☑ 691 \n",
      "Q 134+54  T 188  ☑ 188 \n",
      "Q 2+254   T 256  ☑ 256 \n",
      "Q 511+808 T 1319 ☑ 1319\n",
      "Q 30+879  T 909  ☑ 909 \n",
      "Q 17+583  T 600  ☑ 600 \n",
      "Q 115+197 T 312  ☑ 312 \n",
      "Q 617+7   T 624  ☑ 624 \n",
      "Q 769+37  T 806  ☑ 806 \n",
      "\n",
      "Iteration 28\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.0052 - val_accuracy: 0.9994\n",
      "Q 51+418  T 469  ☑ 469 \n",
      "Q 904+386 T 1290 ☑ 1290\n",
      "Q 727+734 T 1461 ☑ 1461\n",
      "Q 967+4   T 971  ☑ 971 \n",
      "Q 852+428 T 1280 ☑ 1280\n",
      "Q 39+67   T 106  ☑ 106 \n",
      "Q 975+91  T 1066 ☑ 1066\n",
      "Q 545+68  T 613  ☑ 613 \n",
      "Q 621+54  T 675  ☑ 675 \n",
      "Q 791+748 T 1539 ☑ 1539\n",
      "\n",
      "Iteration 29\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0043 - val_accuracy: 0.9994\n",
      "Q 402+7   T 409  ☑ 409 \n",
      "Q 760+324 T 1084 ☑ 1084\n",
      "Q 28+324  T 352  ☑ 352 \n",
      "Q 156+349 T 505  ☑ 505 \n",
      "Q 178+713 T 891  ☑ 891 \n",
      "Q 177+275 T 452  ☑ 452 \n",
      "Q 977+968 T 1945 ☑ 1945\n",
      "Q 431+677 T 1108 ☑ 1108\n",
      "Q 398+39  T 437  ☑ 437 \n",
      "Q 129+5   T 134  ☑ 134 \n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}