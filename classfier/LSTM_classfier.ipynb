{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('tf24': conda)",
   "metadata": {
    "interpreter": {
     "hash": "dfeb4fde596e3a1dcfe636c6f699694a0598ebf6bf1090fe149a85f84a3e4452"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 深層学習での前処理の順序\n",
    "\n",
    "分かち書き・正規化\n",
    "- 単語毎に分割(分かち書き)・正規化(無駄な文字を削除)\n",
    "\n",
    "ここまでをクレンジング(cleansing)という。\n",
    "\n",
    "↓\n",
    "\n",
    "単語埋め込み(Word Embedding)\n",
    "- 単語をベクトル化\n",
    "\n",
    "または、\n",
    "\n",
    "単語をトークン化(Tokenize)\n",
    "- 単語を一意の ID に変換\n",
    "\n",
    "↓\n",
    "\n",
    "パディング(Padding)・端数処理(truncating)\n",
    "\n",
    "↓\n",
    "\n",
    "学習モデルに入力"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "これらは、[言語処理100本ノック 2020 (Rev 2)](https://nlp100.github.io/ja/) にて勉強できる。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "カリフォルニア大学アーバイン校がメンテナンスする559個のデータセットからなるリポジトリ\n",
    "\n",
    "[UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
    "!unzip smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./SMSSpamCollection', sep='\\t', header=None)\n",
    "df.rename({0: 'label', 1: 'text'}, axis=1, inplace=True)\n",
    "df['category'] = df.apply(lambda r: 1 if r['label'] == 'spam' else 0, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## 学習データ分割\n",
    "\n",
    "`sklearn 学習データ 分割`で検索し、`df[['text']], df[['category']]` を `X_train, X_test, Y_train, Y_test` に分割する\n",
    "\n",
    "分析する**文章**を「**`説明変数`**」、予測する**カテゴリー番号**を「**`目的変数`**」とする。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test の shape(要素数) を見る"
   ]
  },
  {
   "source": [
    "## 文章をシーケンス化\n",
    "\n",
    "keras の `fit_on_texts()` メソッドで「説明変数」のトレインデータとテストデータをベクトル化し、`texts_to_sequences` を使い `x_train`,`x_test`という変数名の行列にする。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## パディング\n",
    "\n",
    "説明変数のトレインデータとテストデータを`x_train`,`x_test`という変数名でパディングする"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## モデル定義\n",
    "\n",
    "`Sequential`モデルでLSTMを構築する。\n",
    "\n",
    "語彙数 = `tokenizer.word_index`(インデックス番号)の長さ\n",
    "\n",
    "`Embedding(vocabulary_size,32)`->`LSTM(16)`->`Dense(1)`\n",
    "\n",
    "`compile`で\n",
    "\n",
    "- 損失関数：バイナリクロスエントロピー\n",
    "- 最適化アルゴリズム：Adam(学習率=0.001)\n",
    "- 評価関数のリスト：`['accuracy']`\n",
    "\n",
    "`summary()`でモデルを可視化"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 学習\n",
    "\n",
    "目的変数の値をトレイン・テストとも`.values`でデータフレームから配列に変換する。\n",
    "\n",
    "`fit()`で学習を行う。\n",
    "説明変数と目的変数のトレインデータ、バッチサイズ(32)、エポック数(5)、検証データ(損失とモデル評価関数の性能を評価する)として説明変数と目的変数をいれる"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## モデル評価\n",
    "\n",
    "### サンプルを入力してみる\n",
    "サンプルテキストの配列を作り、ベクトル化せずシーケンス化、パディングする。\n",
    "`predict_classes()`に入力すると評価できる。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Are you single? Use this site to find women in their 20s who want to have sex right away! Pay $ 100 Now and Get FREE! 08717890890\",\n",
    "    \"Are you single? Use this site to find women in their 20s who want to have sex right away! Pay $ 100 Now and Get FREE! 08717890890 http://porn.sex/xxx.asp?o=13543\",\n",
    "    \"Hello. It is nice weather. It's time to see the cherry blossoms, so how about cherry blossom viewing together\"\n",
    "]"
   ]
  },
  {
   "source": [
    "### 精度、再現率、F値を計算\n",
    "\n",
    "`predict()`で入力サンプルに対する予測値の出力を生成する。説明変数のテストデータを入力。\n",
    "\n",
    "`confusion_matrix()`で\n",
    "\n",
    "混合行列 = 目的変数のテストデータと予測値\n",
    "\n",
    "tn, fp, fn, tp = 目的変数のテストデータと予測値 + ravel()メソッド"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"精度(Precision): {:.2f}%\".format(100 * precision_score(y_test, y_predict.round())))\n",
    "print(\"再現率(Recall): {:.2f}%\".format(100 * recall_score(y_test, y_predict.round())))\n",
    "print(\"F値(F1 Score): {:.2f}%\".format(100 * f1_score(y_test,y_predict.round())))"
   ]
  },
  {
   "source": [
    "### ヒートマップで混合行列を図示する\n",
    "\n",
    "`sns.heatmap(混合行列、annot=True(値を表示), cmap='Blue'(配色を青色に), fmt='d'(値を整数))`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "ax= plt.subplot()\n",
    "\n",
    "#annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');\n",
    "ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');\n",
    "ax.xaxis.set_ticklabels(['Not Spam', 'Spam']); ax.yaxis.set_ticklabels(['Not Spam', 'Spam']);"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}